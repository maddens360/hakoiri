# news_bot.py

# ==============================================================================
# å¿…è¦ãªPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# ==============================================================================
# pip install requests beautifulsoup4 openai feedparser
# ==============================================================================
# ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã™ã‚‹æƒ…å ± (GitHub Actionsã®Secretsã«è¨­å®š)
# 1. OPENAI_API_KEY: OpenAIã®APIã‚­ãƒ¼
# 2. LINE_CHANNEL_ACCESS_TOKEN: LINE Messaging APIã®ãƒãƒ£ãƒãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³
# 3. LINE_USER_ID: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ãŸã„LINEãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ID
# 4. YAHOO_RSS_URL: å–å¾—ã—ãŸã„Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰URL
# ==============================================================================

import os
import requests
import feedparser
from bs4 import BeautifulSoup
from openai import OpenAI
from datetime import datetime
import time # é€£ç¶šAPIå‘¼ã³å‡ºã—ã‚’é¿ã‘ã‚‹ãŸã‚ã«ä½¿ç”¨

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ãªã©ã‚’å–å¾—
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_USER_ID = os.environ.get("LINE_USER_ID")
YAHOO_RSS_URL = os.environ.get("YAHOO_RSS_URL", 'https://news.yahoo.co.jp/rss/topics/top-picks.xml')


# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
try:
    if OPENAI_API_KEY:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    else:
        raise ValueError("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
except Exception as e:
    print(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    exit()

# ------------------------------------------------------------------------------
# é–¢æ•°1: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¤‡æ•°ä»¶å–å¾—ã™ã‚‹ (ä¿®æ­£ç‚¹)
# ------------------------------------------------------------------------------
def get_latest_news_from_rss(rss_url, count=3):
    """
    Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’æœ€å¤§countä»¶å–å¾—ã—ã¾ã™ã€‚
    æˆ»ã‚Šå€¤: [{'title': '...', 'url': '...'}, ...] ã®ãƒªã‚¹ãƒˆ
    """
    print(f"RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ä¸­: {rss_url} (æœ€æ–°{count}ä»¶)")
    try:
        feed = feedparser.parse(rss_url)
        
        if not feed.entries:
            print("ã‚¨ãƒ©ãƒ¼: RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return []

        # æœ€æ–°ã®è¨˜äº‹ã‹ã‚‰æŒ‡å®šä»¶æ•°ï¼ˆcountï¼‰åˆ†ã‚’å–å¾—
        news_list = []
        for entry in feed.entries[:count]:
            news_list.append({
                'title': entry.title,
                'url': entry.link
            })
            print(f"è¨˜äº‹å–å¾—: {entry.title}")
            
        return news_list

    except Exception as e:
        print(f"RSSå–å¾—ã¾ãŸã¯è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

# ------------------------------------------------------------------------------
# é–¢æ•°2: ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æœ¬æ–‡ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ (å¤‰æ›´ãªã—)
# ------------------------------------------------------------------------------
def scrape_article_body(url):
    """
    æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰HTMLã‚’å–å¾—ã—ã€BeautifulSoupã§è¨˜äº‹æœ¬æ–‡ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    ï¼ˆå‰å›ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
    """
    print(f"è¨˜äº‹æœ¬æ–‡ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: {url}")
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æœ¬æ–‡ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œ
        paragraphs = soup.find_all('p', class_=lambda x: x and ('sc-' in x or 'article_body' in x))
        
        if not paragraphs:
            article_body_div = soup.find('div', class_='article_body') 
            if article_body_div:
                 paragraphs = article_body_div.find_all('p')

        if not paragraphs:
            print("è­¦å‘Š: è¨˜äº‹æœ¬æ–‡ã®ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚HTMLå…¨ä½“ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™ã€‚")
            main_content = soup.find('main')
            return main_content.get_text(separator='\n', strip=True) if main_content else soup.get_text(separator='\n', strip=True)

        article_text = "\n".join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])
        
        # GPT APIã®å…¥åŠ›åˆ¶é™ã‚’è€ƒæ…®ã—ã€é•·ã™ãã‚‹å ´åˆã¯ã‚«ãƒƒãƒˆ
        MAX_CHARS = 3000
        if len(article_text) > MAX_CHARS:
            article_text = article_text[:MAX_CHARS] + "..."
            
        return article_text

    except requests.exceptions.RequestException as req_err:
        print(f"HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {req_err}")
        return None
    except Exception as e:
        print(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# ------------------------------------------------------------------------------
# é–¢æ•°3: OpenAI GPT APIã§è¦ç´„ã¨ãƒ•ãƒªã‚¬ãƒŠãƒ»å˜èªè§£èª¬ã‚’ç”Ÿæˆã™ã‚‹ (ä¿®æ­£ç‚¹)
# ------------------------------------------------------------------------------
def summarize_and_add_furigana(title, article_text):
    """
    è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’GPT APIã«é€ã‚Šã€è¦ç´„ã€ãƒ•ãƒªã‚¬ãƒŠã€å˜èªè§£èª¬ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
    if not article_text:
        return "è¨˜äº‹æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€è¦ç´„ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    print("GPT APIã«è¦ç´„ã¨ãƒ•ãƒªã‚¬ãƒŠãƒ»å˜èªè§£èª¬ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆAIã¸ã®æŒ‡ç¤ºï¼‰ã®ä½œæˆã‚’ä¿®æ­£
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’èª­ã¿ã€ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    
    ã€è¦ä»¶ã€‘
    1. è¨˜äº‹ã®å†…å®¹ã‚’**3è¡Œä»¥å†…**ã§ã€åˆ†ã‹ã‚Šã‚„ã™ã**è¦ç´„**ã—ã¦ãã ã•ã„ã€‚
    2. è¦ç´„æ–‡ã®ä¸­ã§ã€**é›£ã—ã„æ¼¢å­—ã€å°‚é–€ç”¨èªã€äººåã€åœ°å**ã«ã®ã¿ã€æ‹¬å¼§æ›¸ãã§**ãƒ•ãƒªã‚¬ãƒŠ**ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚å…¨ã¦ã®æ¼¢å­—ã«ãƒ•ãƒªã‚¬ãƒŠã‚’ä»˜ã‘ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    3. è¨˜äº‹æœ¬æ–‡ã«å«ã¾ã‚Œã‚‹**é›£ã—ã„å°‚é–€ç”¨èª**ã‚„**é¦´æŸ“ã¿ã®è–„ã„å˜èª**ãŒã‚ã‚Œã°ã€ãã®**æ„å‘³ã‚’ç°¡æ½”ã«**ä¸€è¡Œã§è£œè¶³ã—ã¦ãã ã•ã„ï¼ˆè£œè¶³ãŒãªã„å ´åˆã¯[å˜èªè§£èª¬]ã‚»ã‚¯ã‚·ãƒ§ãƒ³è‡ªä½“ã‚’çœç•¥ã—ã¦ãã ã•ã„ï¼‰ã€‚
    
    ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    [è¦ç´„]
    è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ1è¡Œç›®ï¼ˆãƒ•ãƒªã‚¬ãƒŠã‚’é©åˆ‡ã«ä»˜ä¸ï¼‰
    è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ2è¡Œç›®
    è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ3è¡Œç›®
    
    [å˜èªè§£èª¬]
    ï¼ˆè£œè¶³ãŒå¿…è¦ãªå ´åˆã®ã¿è¨˜è¼‰ï¼‰å˜èª: æ„å‘³
    
    ---
    
    ã€è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã€‘
    {title}
    
    ã€è¨˜äº‹æœ¬æ–‡ã€‘
    {article_text}
    """

    try:
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo", # ã‚³ã‚¹ãƒˆåŠ¹ç‡ã¨é€Ÿåº¦ã‚’è€ƒæ…®
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã§ã™ã€‚æƒ…å ±ã‚’æ­£ç¢ºã‹ã¤ç°¡æ½”ã«ã€è¦ªã—ã¿ã‚„ã™ã„è¨€è‘‰ã§ä¼ãˆã¦ãã ã•ã„ã€‚ãƒ•ãƒªã‚¬ãƒŠã¯é›£ã—ã„å˜èªã®ã¿ã«çµã£ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3 # å®‰å®šã—ãŸè¦ç´„ã‚’ç”Ÿæˆ
        )
        
        generated_text = response.choices[0].message.content.strip()
        print("GPT APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        return generated_text

    except Exception as e:
        print(f"OpenAI APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return f"è¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\nã‚¨ãƒ©ãƒ¼å†…å®¹: {e}"

# ------------------------------------------------------------------------------
# é–¢æ•°4: LINE Messaging APIã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹ (å¤‰æ›´ãªã—)
# ------------------------------------------------------------------------------
def send_line_message(user_id, message, token):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼IDã«ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¾ã™ã€‚
    """
    if not user_id or not token:
        print("ã‚¨ãƒ©ãƒ¼: LINE_USER_IDã¾ãŸã¯LINE_CHANNEL_ACCESS_TOKENãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return False
        
    print(f"LINEãƒ¦ãƒ¼ã‚¶ãƒ¼ID {user_id} ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ä¸­...")
    
    url = "https://api.line.me/v2/bot/message/push"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {token}"
    }
    
    data = {
        "to": user_id,
        "messages": [
            {
                "type": "text",
                "text": message
            }
        ]
    }

    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status() 
        
        print("LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡æˆåŠŸï¼")
        return True

    except requests.exceptions.RequestException as req_err:
        print(f"LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {req_err}")
        return False

# ------------------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç† (ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å®Ÿè¡Œé–‹å§‹åœ°ç‚¹) (ä¿®æ­£ç‚¹)
# ------------------------------------------------------------------------------
def main():
    """
    å…¨ä½“ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©ã—ã¾ã™ã€‚ï¼ˆ3è¨˜äº‹åˆ†ã®ãƒ«ãƒ¼ãƒ—å‡¦ç†ã‚’è¿½åŠ ï¼‰
    """
    print(f"--- å‡¦ç†é–‹å§‹: {datetime.now()} ---")
    
    # 1. RSSã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’3ä»¶å–å¾—
    news_list = get_latest_news_from_rss(YAHOO_RSS_URL, count=3)
    
    if not news_list:
        send_line_message(LINE_USER_ID, "ä»Šæœã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", LINE_CHANNEL_ACCESS_TOKEN)
        return

    # è¨˜äº‹ã”ã¨ã®å‡¦ç†çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    all_summaries = []
    
    # å–å¾—ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚’ãƒ«ãƒ¼ãƒ—å‡¦ç†
    for i, news in enumerate(news_list):
        title = news['title']
        url = news['url']
        
        print(f"\n--- è¨˜äº‹ {i+1}/{len(news_list)} ã®å‡¦ç†é–‹å§‹ ---")

        # 2. è¨˜äº‹ã®æœ¬æ–‡ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        article_text = scrape_article_body(url)
        
        # è¨˜äº‹ã”ã¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹æˆ
        article_summary_block = f"ğŸ“° **è¨˜äº‹ {i+1}**ï¼š{title}\n"
        
        if not article_text:
            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—æ™‚ã®å‡¦ç†
            article_summary_block += f"[ã‚¨ãƒ©ãƒ¼] æœ¬æ–‡å–å¾—å¤±æ•—ã€‚URLã‚’ã”ç¢ºèªãã ã•ã„ã€‚\n"
        else:
            # 3. GPT APIã§è¦ç´„ã¨ãƒ•ãƒªã‚¬ãƒŠãƒ»å˜èªè§£èª¬ã‚’ç”Ÿæˆ
            summary_text_raw = summarize_and_add_furigana(title, article_text)
            article_summary_block += summary_text_raw

        article_summary_block += f"\nğŸ”— è¨˜äº‹URL: {url}"
        
        all_summaries.append(article_summary_block)
        
        # é€£ç¶šAPIå‘¼ã³å‡ºã—ã‚’é¿ã‘ã‚‹ãŸã‚ã€æ¬¡ã®è¨˜äº‹å‡¦ç†å‰ã«å°‘ã—å¾…ã¤
        if i < len(news_list) - 1:
            time.sleep(1) # 1ç§’å¾…æ©Ÿ
    
    # 4. 3è¨˜äº‹åˆ†ã®æƒ…å ±ã‚’ã¾ã¨ã‚ã¦LINEã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
    # 3ã¤ã®è¨˜äº‹ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ”¹è¡Œã¨åŒºåˆ‡ã‚Šç·šã§çµåˆ
    all_summaries_joined = '\n\n----------------------------------\n\n'.join(all_summaries)
    final_message = (
        f"ğŸŒ ä»Šæœã®å³é¸ãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(news_list)}æœ¬ ğŸ—ï¸\n"
        f"==================================\n\n"
        f"{all_summaries_joined}" # äº‹å‰ã«çµåˆã—ãŸå¤‰æ•°ã‚’æŒ¿å…¥
        f"\n\n=================================="
    )
    
    # LINEã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ€å¤§æ–‡å­—æ•°ï¼ˆ5000å­—ï¼‰ã®ãƒã‚§ãƒƒã‚¯
    if len(final_message) > 4800:
        final_message = final_message[:4800] + "...\n(ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé•·ã™ãã‚‹ãŸã‚é€”ä¸­ã§çœç•¥ã•ã‚Œã¾ã—ãŸ)"
        
    send_line_message(LINE_USER_ID, final_message, LINE_CHANNEL_ACCESS_TOKEN)
    
    print(f"--- å‡¦ç†å®Œäº†: {datetime.now()} ---")

if __name__ == "__main__":
    main()
